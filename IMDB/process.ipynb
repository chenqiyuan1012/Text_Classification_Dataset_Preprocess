{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n",
      "read test files: 25000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def rm_tags(text):\n",
    "    re_tags = re.compile(r'<[^>]+>')\n",
    "    return re_tags.sub(' ', text)\n",
    "\n",
    "\n",
    "def read_files(filetype):\n",
    "    #path = \"aclImdb/\"\n",
    "    path = \"./\"\n",
    "    file_list = []\n",
    "\n",
    "    positive_path = path + filetype + \"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list += [positive_path + f]\n",
    "\n",
    "    negative_path = path + filetype + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list += [negative_path + f]\n",
    "\n",
    "    print(\"read\", filetype, \"files:\", len(file_list))\n",
    "\n",
    "    all_labels = ([1]*12500+[0]*12500)\n",
    "\n",
    "    all_texts = []\n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding='utf8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "\n",
    "    return all_labels, all_texts\n",
    "\n",
    "\n",
    "y_train, train_text = read_files(\"train\")\n",
    "y_test, test_text = read_files(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filetype):\n",
    "    #path = \"aclImdb/\"\n",
    "    path = \"./\"\n",
    "    file_list = []\n",
    "    if filetype != \"unsup\":\n",
    "        positive_path = path + filetype + \"/pos/\"\n",
    "        for f in os.listdir(positive_path):\n",
    "            file_list += [positive_path + f]\n",
    "\n",
    "        negative_path = path + filetype + \"/neg/\"\n",
    "        for f in os.listdir(negative_path):\n",
    "            file_list += [negative_path + f]\n",
    "\n",
    "        print(\"read\", filetype, \"files:\", len(file_list))\n",
    "\n",
    "        all_labels = ([1]*12500+[0]*12500)\n",
    "\n",
    "    else:\n",
    "        text_path = path+'/'+filetype+'/'\n",
    "        for f in os.listdir(text_path):\n",
    "            file_list += [text_path + f]\n",
    "    all_texts = []\n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding='utf8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "\n",
    "    if filetype != 'unsup':\n",
    "        return all_labels, all_texts\n",
    "    else:\n",
    "        return all_texts\n",
    "\n",
    "\n",
    "unsup_text = read_files(\"unsup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sup_dict = {'label': y_train, 'sentence': train_text}\n",
    "test_dict = {'label': y_test, 'sentence': test_text}\n",
    "unsup_dict = {'sentence': unsup_text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_sup_df = pd.DataFrame.from_dict(train_sup_dict)\n",
    "test_df = pd.DataFrame.from_dict(test_dict)\n",
    "unsup_df = pd.DataFrame.from_dict(unsup_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                 sentence\n",
       "0      This movie is hilarious! It is just so funny. ...\n",
       "1      Firstly, this is a film that is really about m...\n",
       "2      Is the movie in ENGLISH? I have seen a lot of ...\n",
       "3      So here we are watching home movies? No. No on...\n",
       "4      James Caan must be wondering why he agreed to ...\n",
       "...                                                  ...\n",
       "49995  After THIS GUN FOR HIRE, Paramount realized th...\n",
       "49996  I've seen many of the movies made about the li...\n",
       "49997  I thought this movie was very good -- thought ...\n",
       "49998  The song was awesome. Bobbie Gentry song is cl...\n",
       "49999  One of the best in adult anime, this one has i...\n",
       "\n",
       "[50000 rows x 1 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sup_df.to_csv('train_sup.csv', index=False)\n",
    "unsup_df.to_csv('unsup.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' train_2500 = shuffle(pd.concat([train0, train1]))\\ntrain_500 = shuffle(pd.concat(train0.sample(250), train1.sample(250)))\\ntrain_20 = shuffle(pd.concat(train0.sample(10), train1.sample(10))) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以上仅仅完成了将数据集处理成csv文件，接下来按照模型要求处理数据集\n",
    "# 模型要求：70000个无监督数据，20/500/2500个训练数据，250000个测试数据\n",
    "\n",
    "# 对于测试数据，保持不变，对于训练数据，分为两部分，一部分是无监督数据，一部分是有监督数据\n",
    "# 从训练数据中，采样2500个训练数据，并下采样至500个，再下采样至20个，最后将剩余的和无监督混合\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "path = \"./model_require/\"\n",
    "\n",
    "folder = os.path.exists(path)\n",
    "if not folder:\n",
    "    os.makedirs(path)\n",
    "\n",
    "train = pd.read_csv('train_sup.csv')\n",
    "# 不使用sample而是用shuffle是因为，这样可以便于将无监督数据分离出来\n",
    "label0, label1 = shuffle(train[train['label'].isin([0])]), shuffle(\n",
    "    train[train['label'].isin([1])])\n",
    "train0, unsup0 = label0[:1250], label0[1250:]  # isin仅可提供一个list，所以0需要用list来表示\n",
    "train1, unsup1 = label1[:1250], label1[1250:]\n",
    "shuffle(pd.concat([train0, train1], ignore_index=True)\n",
    "        ).to_csv(path+'train_2500.csv', index=False)\n",
    "shuffle(pd.concat([train0.sample(250), train1.sample(250)], ignore_index=True)\n",
    "        ).to_csv(path+'train_500.csv', index=False)\n",
    "shuffle(pd.concat([train0.sample(10), train1.sample(10)], ignore_index=True)\n",
    "        ).to_csv(path+'train_20.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup = pd.read_csv('unsup.csv')\n",
    "unsup = pd.concat([unsup, pd.DataFrame(pd.concat(\n",
    "    [unsup0[:10000], unsup1[:10000]], ignore_index=True), columns=['sentence'])], ignore_index=True)\n",
    "shuffle(unsup).to_csv(path+'unsup.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "data=shuffle(test)\n",
    "dev=data[5000:10000]\n",
    "test=data[:5000]\n",
    "test.to_csv(path+'test.csv', index=False)# 对测试数据进行打乱\n",
    "dev.to_csv(path+'dev.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eb355fea5b34207108c8fb105aa87cf13e5d16c4958c36316ec35e2a0cc3fa0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
